{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mrSe1C2eQIzR"
   },
   "source": [
    "# DCGAN: Deep Convolutional GAN\n",
    "\n",
    "In this lab you are going to code a Deep Convolutional GAN (DCGAN), aka a GAN made of convolutions. As we are trying to generate images, convolutions are the perfect layer to use.\n",
    "\n",
    "This lab is quite RAM & GPU intensive, thus we recommand you to run in a Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "deJlteppOgsG",
    "outputId": "f8f4e638-2cd6-43fa-e41a-dd537c7c4006"
   },
   "outputs": [],
   "source": [
    "WORK_ON_COLAB = True\n",
    "\n",
    "if WORK_ON_COLAB:\n",
    "    try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "SpH_M1kMOZvs",
    "outputId": "239232f6-fb5f-4b7b-839b-4db0324d33d7"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a30CAGsXQkAy"
   },
   "source": [
    "## Data\n",
    "\n",
    "We are download our grayscale dataset (it could be either MNIST or Fashion-MNIST). Note that we are resizing images to a larger scale to match the original paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ANjuxKp9OZv_"
   },
   "outputs": [],
   "source": [
    "(images, labels), (_, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8ifY67raOZwL",
    "outputId": "3070c114-7e99-4668-bb3e-7091654afda5"
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "images = resize(images, (images.shape[0], 64, 64, 1), preserve_range=True).astype(\"float32\")\n",
    "images = (images - 127.5) / 127.5\n",
    "\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UfDcsM5nOZwY"
   },
   "outputs": [],
   "source": [
    "data_generator = tf.data.Dataset.from_tensor_slices(\n",
    "    images).shuffle(60000).batch(100, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tROMZuCMOZwi"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display(images, row=2, col=10):\n",
    "    fig = plt.figure(figsize=(20, 3))\n",
    "    it = 0\n",
    "    for r in range(row):\n",
    "        for c in range(col):\n",
    "            ax = plt.subplot(row, col, it + 1)\n",
    "            ax.set_axis_off()\n",
    "            ax.imshow(images[it, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "            it += 1\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "colab_type": "code",
    "id": "znZpg2RWOZws",
    "outputId": "533fc1f6-46e2-465b-da89-082c3fafa755"
   },
   "outputs": [],
   "source": [
    "display(images);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MH0F6r-gRAKN"
   },
   "source": [
    "# Exercice\n",
    "\n",
    "Code the generator and the discriminator:\n",
    "\n",
    "### 1. Generator:\n",
    "\n",
    "- Input noise of (1, 1, 100)\n",
    "- Transpose convolution of 1024 channels, kernel of 4, stride 1 and valid padding; followed by a BatchNorm and a LeakyReLU of 0.2\n",
    "- Transpose convolution with kernel of 4, stride 2 and same padding; followed by a BatchNorm and a LeakyReLU of 0.2. All of this line repeated 3 times with 512, 256, and 128 channels respectively.\n",
    "- A final transpose convolution with a kernel of 4, a stride of 2, a same padding.\n",
    "\n",
    "Questions: Which activation for the last conv? How many channels?\n",
    "\n",
    "### 2. Discriminator:\n",
    "\n",
    "- Image input\n",
    "- Four block of Conv (kernel 4, stride 2, padding same) + BatchNorm + LeakyReLU with respectively 128, 256, 512, and 1024 channels.\n",
    "\n",
    "Questions: What additional layer is needed to have a scalar output? Which activation to use?\n",
    "\n",
    "Finally why did we use LeakyReLU instead of ReLU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5266izYAhRN"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import BatchNormalization, Input\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import # TODO one more layer is needed for discriminator end\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "def get_generator():\n",
    "    # TODO\n",
    "    \n",
    "    return Model(inputs=input_noise, outputs=x)\n",
    "\n",
    "\n",
    "def get_discriminator():\n",
    "    # TODO\n",
    "\n",
    "    return Model(inputs=input_image, outputs=x)\n",
    "\n",
    "\n",
    "generator = get_generator()\n",
    "discriminator = get_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/dcgan.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UsZTPjDGUGu6"
   },
   "source": [
    "Now that our models are created, a sanity check must be done on the output dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "O9lmiX_bOZxO",
    "outputId": "45deb64f-b63d-4c6f-ab67-c59a6e69fa0e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_noise(batch_size, nz=100):\n",
    "    return tf.random.normal([batch_size, 1, 1, nz])\n",
    "\n",
    "noise = get_noise(20)\n",
    "\n",
    "print(\"init\", noise.shape)\n",
    "fake_images = generator(noise)\n",
    "print(\"Fake images\", fake_images.shape)  # Should be (_, 64, 64, 1)\n",
    "preds = discriminator(fake_images)\n",
    "print(\"Predictions\", preds.shape)  # Should be (_, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oa0yr0aUGyCV"
   },
   "outputs": [],
   "source": [
    "# generator.summary()\n",
    "# discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KKOYEtHJUdgW"
   },
   "source": [
    "Two losses are needed:\n",
    "\n",
    "1. The discriminator must classify original images as real and generated images as fake.\n",
    "2. The generator must force the discriminator to classify its generated images as real.\n",
    "\n",
    "Note that we are using the `binary_crossentropy` with the options `from_logits=True` so that the loss include itself the sigmoid activation.\n",
    "\n",
    "Fill the following losses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ikqmWFOOZxX"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "\n",
    "def discriminator_loss(preds_real, preds_fake):\n",
    "    loss_real = # TODO\n",
    "    loss_fake = # TODO\n",
    "    return loss_real + loss_fake\n",
    "\n",
    "\n",
    "def generator_loss(preds_fake):\n",
    "    return # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/gan_losses.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dNos30JRYKAb"
   },
   "source": [
    "We create two optimizers, one for the discriminator and one for the generator. Remember that Adam keeps variables about the model, and thus cannot be shared as a SGD could."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DZQBLUTVYJSf"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "optimizer_d = Adam(learning_rate=1e-4, beta_1=0.5)\n",
    "optimizer_g = Adam(learning_rate=1e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6YobxKNcYX5p"
   },
   "source": [
    "We define our train step for a single batch. Fill the missing part.\n",
    "\n",
    "Note that we use the decorator `tf.function` to \"compile\" the function and speed up a bit the training. This decorator should always be placed on top of computationaly intensive functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HzGiUcZh09E9"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = get_noise(images.shape[0])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = # TODO\n",
    "        \n",
    "        real_output = # TODO\n",
    "        fake_output = # TODO\n",
    "\n",
    "        gen_loss = # TODO\n",
    "        disc_loss = # TODO\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    optimizer_g.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    optimizer_d.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return disc_loss, gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/gan_step.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2wafgOpVYsx6"
   },
   "source": [
    "We can now train our DCGAN.\n",
    "\n",
    "Monitor the losses of our model. Beware that one doesn't converge to 0 while the other diverge. It would be mean that the \"adverserial\" part of the training is biased in favor of one of the model.\n",
    "\n",
    "In less than 5 epochs you should see realist digits. In 30 epochs your model should have converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Iva_8cuROZxv",
    "outputId": "29cc304f-c306-4fe8-83f9-4498d7799f4d"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Mean\n",
    "from IPython.core.display import display as jupy_display\n",
    "import numpy as np\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "fixed_noise = get_noise(20)\n",
    "\n",
    "print(\"Base noise:\")\n",
    "fake_images = generator(fixed_noise, training=False).numpy()\n",
    "jupy_display(display(fake_images))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"====== Epoch {:2d} ======\".format(epoch))\n",
    "\n",
    "    epoch_loss_d = Mean()\n",
    "    epoch_loss_g = Mean()\n",
    "    \n",
    "    epoch_len = tf.data.experimental.cardinality(data_generator)\n",
    "    for i, real_images in enumerate(data_generator):\n",
    "        loss_d, loss_g = train_step(real_images)\n",
    "        epoch_loss_d(loss_d)\n",
    "        epoch_loss_g(loss_g)\n",
    "        \n",
    "        if i % 50 == 0 and i > 0:\n",
    "            print(i, end=\" ... \")\n",
    "            \n",
    "    print(\"\\nDiscriminator: {}, Generator: {}\".format(\n",
    "        epoch_loss_d.result(), epoch_loss_g.result()))\n",
    "    fake_images = generator(fixed_noise, training=False).numpy()\n",
    "    jupy_display(display(fake_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "- Interpret your result\n",
    "- What is the two main problems the model have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xQlNzQu7ZE7p"
   },
   "source": [
    "# Homework\n",
    "\n",
    "- Try more epochs to have crisper images.\n",
    "- Try other datasets, like celeba. Beware of the number of channels.\n",
    "- Modify this network to make a cDCGAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eqfYNemZZay9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Deep Convolutional GAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
